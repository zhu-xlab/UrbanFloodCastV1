{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8085f3d-b479-4006-978b-dda90d982a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import datetime\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "\n",
    "from models.FNO import FNO2d, FNO3d\n",
    "from models.Unet import UNet2d, UNet3d\n",
    "# from models.GFNO_steerable import GFNO2d_steer\n",
    "# from models.Unet import Unet_Rot, Unet_Rot_M, Unet_Rot_3D\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import imageio\n",
    "import pandas as pd\n",
    "from models.DNO import DNO\n",
    "\n",
    "from utils25 import flood_data, LpLoss, nse, corr, critical_success_index\n",
    "\n",
    "import scipy\n",
    "import numpy as np\n",
    "from timeit import default_timer\n",
    "import argparse\n",
    "from torch.utils.tensorboard import SummaryWriter as writer\n",
    "import torch\n",
    "import h5py\n",
    "import xarray as xr\n",
    "from tqdm import tqdm\n",
    "from openpyxl import load_workbook#####\n",
    "import io\n",
    "import os\n",
    "import tifffile as tiff\n",
    "import torch.nn.functional as F\n",
    "from dataset import flood_data\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"5\"\n",
    "torch.set_num_threads(1)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:5\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "def get_eval_pred(model, x, strategy, T, times):\n",
    "\n",
    "    if strategy == \"oneshot\":\n",
    "        pred = model(x)\n",
    "    else:\n",
    "\n",
    "        for t in range(T):\n",
    "            t1 = default_timer()\n",
    "            im = model(x)\n",
    "            times.append(default_timer() - t1)\n",
    "            if t == 0:\n",
    "                pred = im\n",
    "            else:\n",
    "                pred = torch.cat((pred, im), -2)\n",
    "            if strategy == \"markov\":\n",
    "                x = im\n",
    "            else:\n",
    "                x = torch.cat((x[..., 1:, :], im), dim=-2)\n",
    "\n",
    "    return pred\n",
    "\n",
    "################################################################\n",
    "# configs\n",
    "################################################################\n",
    "zoom_factor=5\n",
    "width=int(3212/zoom_factor)\n",
    "height=int(2727/zoom_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06cf66fd-5f00-451c-91c4-97d78b22eb06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration saved in args and ready to use!\n"
     ]
    }
   ],
   "source": [
    "from argparse import Namespace\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Save all settings in args\n",
    "args = Namespace(\n",
    "    results_path=\"/home/sirui/INNOMAUS/UrbanFloodCast/UrbanFloodCast/DNO/results/\",\n",
    "    suffix=\"seed1\",\n",
    "    txt_suffix=\"Flood_DNO_Layers_oneset_seed1_t5\",\n",
    "    super_res=False,\n",
    "    verbose=True,\n",
    "    T=24,  # number of timesteps to predict\n",
    "    ntrain=116,  # training sample size\n",
    "    nvalid=12,  # valid sample size\n",
    "    ntest=17,  # test sample size\n",
    "    nsuper=None,\n",
    "    seed=1,\n",
    "    model_type='DNO',\n",
    "    depth=4,\n",
    "    modes=12,\n",
    "    width=20,\n",
    "    Gwidth=10,  # hidden dimension of equivariant layers if model_type=hybrid\n",
    "    n_equiv=3,  # number of equivariant layers if model_type=hybrid\n",
    "    reflection=False,  # symmetry group p4->p4m for data augmentation\n",
    "    grid=None,  # [\"symmetric\", \"cartesian\", None]\n",
    "    epochs=500,\n",
    "    early_stopping=50,  # stop if validation error does not improve for successive epochs\n",
    "    batch_size=1,\n",
    "    learning_rate=0.001,\n",
    "    step=False,  # use step scheduler\n",
    "    gamma=0.5,  # gamma for step scheduler\n",
    "    step_size=None,  # step size for step scheduler\n",
    "    lmbda=0.0001,  # weight decay for adam\n",
    "    strategy=\"oneshot\",  # markov, recurrent, or oneshot\n",
    "    time_pad=False,  # pad the time dimension for strategy=oneshot\n",
    "    noise_std=0.00,  # amount of noise to inject for strategy=markov\n",
    "    root='/home/sirui/INNOMAUS/UrbanFloodCast/UrbanFloodCast/DNO/save/',#model path\n",
    ")\n",
    "# SR dataset\n",
    "dem_tif_path = '/home/sirui/INNOMAUS/2025_new/dem/DEM.tif'\n",
    "Path_test = \"/home/sirui/INNOMAUS/2025_new/pt/test2\"\n",
    "# Validate inputs\n",
    "assert args.model_type in [\"FNO2d\", \"FNO2d_aug\", \"FNO3d\", \"FNO3d_aug\", \"UNet2d\", \"UNet3d\", \"DNO\"], \\\n",
    "    f\"Invalid model type {args.model_type}\"\n",
    "assert args.strategy in [\"teacher_forcing\", \"markov\", \"recurrent\", \"oneshot\"], \"Invalid training strategy\"\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "torch.cuda.manual_seed(args.seed)\n",
    "random.seed(args.seed)\n",
    "\n",
    "# Define additional parameters based on model type and grid\n",
    "args.data_aug = \"aug\" in args.model_type\n",
    "\n",
    "# FNO data specs\n",
    "args.Sy = height\n",
    "args.Sx = width\n",
    "args.S = 64  # spatial resolution\n",
    "args.S_super = 4 * args.S  # super spatial resolution\n",
    "args.T_in = 1  # number of input times\n",
    "args.T_super = 4 * args.T  # prediction temporal super resolution\n",
    "args.d = 2  # spatial resolution\n",
    "num_channels = 5\n",
    "args.num_channels_y = 3\n",
    "\n",
    "# Adjust data specs based on model type and data path\n",
    "args.threeD = args.model_type in [\"FNO3d\", \"Unet_Rot_3D\", \"DNO\", \"UNet3d\"]\n",
    "args.swe = False\n",
    "args.rdb = False\n",
    "args.grid_type = \"cartesian\" if not args.grid else args.grid\n",
    "\n",
    "# Validate grid type\n",
    "if args.grid:\n",
    "    assert args.grid in ['symmetric', 'cartesian', 'None']\n",
    "\n",
    "args.time_modes = None\n",
    "time1 = args.strategy == \"oneshot\"  # perform convolutions in space-time\n",
    "if time1 and not args.time_pad:\n",
    "    args.time_modes = 5 if args.swe else 8  # Adjust based on T\n",
    "elif time1 and args.swe:\n",
    "    args.time_modes = 8\n",
    "\n",
    "# Training configurations\n",
    "initial_step = 1 if args.strategy == \"markov\" else args.T_in\n",
    "\n",
    "# Paths\n",
    "args.path_model = os.path.join(args.root, 'model.pt')\n",
    "data_aug = \"aug\" in args.model_type\n",
    "\n",
    "# FNO data specs\n",
    "Sy = height\n",
    "Sx = width\n",
    "S = 64 # spatial res\n",
    "S_super = 4 * S # super spatial res\n",
    "T_in = 1 # number of input times\n",
    "T = args.T\n",
    "T_super = 4 * T # prediction temporal super res\n",
    "d = 2 # spatial res\n",
    "num_channels = 5\n",
    "num_channels_y = 3\n",
    "\n",
    "# adjust data specs based on model type and data path\n",
    "threeD = args.model_type in [\"FNO3d\",\n",
    "                             \"Unet_Rot_3D\", \"DNO\", \"UNet3d\"]\n",
    "swe = False\n",
    "rdb = False\n",
    "grid_type = \"cartesian\"\n",
    "if args.grid:\n",
    "    grid_type = args.grid\n",
    "    assert grid_type in ['symmetric', 'cartesian', 'None']\n",
    "\n",
    "\n",
    "ntrain = args.ntrain \n",
    "nvalid = args.nvalid\n",
    "ntest = args.ntest \n",
    "\n",
    "time_modes = None\n",
    "time1 = args.strategy == \"oneshot\" # perform convolutions in space-time\n",
    "if time1 and not args.time_pad:\n",
    "    time_modes = 5 if swe else 8 # 6 is based on T=10\n",
    "elif time1 and swe:\n",
    "    time_modes = 8\n",
    "\n",
    "modes = args.modes\n",
    "width = args.width\n",
    "n_layer = args.depth\n",
    "batch_size = args.batch_size\n",
    "\n",
    "epochs = args.epochs # 500\n",
    "learning_rate = args.learning_rate\n",
    "scheduler_step = args.step_size\n",
    "scheduler_gamma = args.gamma # for step scheduler\n",
    "\n",
    "initial_step = 1 if args.strategy == \"markov\" else T_in\n",
    "print(\"Configuration saved in args and ready to use!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a118c98-0101-4510-8440-fda9a5bd9210",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################\n",
    "# Model init\n",
    "################################################################\n",
    "if args.model_type in [\"FNO2d\", \"FNO2d_aug\"]:\n",
    "    model = FNO2d(num_channels=num_channels, initial_step=initial_step, modes1=modes, modes2=modes, width=width,\n",
    "                  grid_type=grid_type).to(device)#.cuda()\n",
    "elif args.model_type in [\"FNO3d\", \"FNO3d_aug\"]:\n",
    "    modes3 = time_modes if time_modes else modes\n",
    "    model = FNO3d(num_channels=num_channels, initial_step=initial_step, modes1=modes, modes2=modes, modes3=modes3,\n",
    "                  width=width, time=time1, time_pad=args.time_pad).to(device)#.cuda()\n",
    "elif args.model_type == \"DNO\":\n",
    "    model = DNO(num_channels=num_channels, width=10, initial_step=initial_step, pad=args.time_pad, factor=1).to(device)#.cuda()\n",
    "elif args.model_type == \"UNet3d\":\n",
    "    model = UNet3d(in_channels=initial_step * num_channels, out_channels=num_channels_y, init_features=32,\n",
    "                   grid_type=grid_type, time=time1).to(device)#.cuda()\n",
    "else:\n",
    "    raise NotImplementedError(\"Model not recognized\")\n",
    "\n",
    "################################################################\n",
    "# load data\n",
    "# Input: DEM/Initial conditions/Rainfall/coords\n",
    "################################################################\n",
    "full_data = None # for superres\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0486267f-4d16-4aa0-acc0-67b2e6ee52dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_data = flood_data(path_root=Path_test, train=False, strategy=args.strategy, T_in=T_in, T_out=T)\n",
    "ntest = len(test_data)\n",
    "print('ntest', ntest)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "path_model = os.path.join(args.root, 'model.pt')\n",
    "\n",
    "complex_ct = sum(par.numel() * (1 + par.is_complex()) for par in model.parameters())\n",
    "real_ct = sum(par.numel() for par in model.parameters())\n",
    "# Assuming complex_ct and real_ct are tensors or potentially non-scalar\n",
    "if args.verbose:\n",
    "    print(f\"{args.model_type}; # Params: complex count {complex_ct}, real count: {real_ct}\")\n",
    "lploss = LpLoss(size_average=False)\n",
    "\n",
    "# test\n",
    "##FNO\n",
    "#model.load_state_dict(torch.load(path_model))\n",
    "## Other models\n",
    "checkpoint = torch.load(path_model,map_location='cuda')\n",
    "state_dict = checkpoint['state_dict']\n",
    "model.load_state_dict(state_dict)\n",
    "print(model)\n",
    "model.eval()\n",
    "test_l2 = test_vort_l2 = test_pres_l2 = test_nse = test_corr = test_csi_1 = test_csi_2 = test_csi_3 = 0#define variable\n",
    "rotations_l2 = 0\n",
    "reflections_l2 = 0\n",
    "test_rt_l2 = 0\n",
    "test_rf_l2 = 0\n",
    "test_loss_by_channel = None\n",
    "key = 0\n",
    "i = 0\n",
    "total_time = 0\n",
    "sample_count = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for xx, yy, mask in test_loader:\n",
    "        xx = xx.to(device)#input runoff\n",
    "        yy = yy.to(device)#ground truth for giving the result metrics\n",
    "        mask = mask.to(device)\n",
    "        yy = yy * mask\n",
    "        input_data = xx\n",
    "        # Start\n",
    "        start_time = time.time()\n",
    "        pred = get_eval_pred(model=model, x=xx, strategy=args.strategy, T=T, times=[]).view(len(xx), Sy, Sx, T, num_channels_y)\n",
    "        # End\n",
    "        end_time = time.time()\n",
    "        batch_time = end_time - start_time\n",
    "        total_time += batch_time\n",
    "        sample_count += len(xx)\n",
    "        # print(f\"Average prediction time per sample: {batch_time:.4f} seconds, lens of samples: {len(xx)}\")\n",
    "\n",
    "        pred = pred * mask\n",
    "        # print('pred', pred.shape)\n",
    "        test_l2 += lploss(pred.reshape(len(pred), -1, num_channels_y), yy.reshape(len(yy), -1, num_channels_y)).item()\n",
    "        test_nse += nse(pred.reshape(len(pred), -1, num_channels_y), yy.reshape(len(yy), -1, num_channels_y)).item()\n",
    "        test_corr += corr(pred.reshape(len(pred), -1, num_channels_y), yy.reshape(len(yy), -1, num_channels_y)).item()\n",
    "        test_csi_1 += critical_success_index(pred[..., 0:1].reshape(len(pred), -1, 1),\n",
    "                                             yy[..., 0:1].reshape(len(yy), -1, 1), 0.01).item()\n",
    "        test_csi_2 += critical_success_index(pred[..., 0:1].reshape(len(pred), -1, 1),\n",
    "                                             yy[..., 0:1].reshape(len(yy), -1, 1), 0.1).item()\n",
    "        test_csi_3 += critical_success_index(pred[..., 0:1].reshape(len(pred), -1, 1),\n",
    "                                             yy[..., 0:1].reshape(len(yy), -1, 1), 0.5).item()\n",
    "        \n",
    "print('sample_count', sample_count)\n",
    "print('ntest', ntest)\n",
    "average_time_per_sample = total_time / sample_count if sample_count > 0 else 0\n",
    "test_time_l2 = test_space_l2 = ntest_super = test_int_space_l2 = test_int_time_l2 = None\n",
    "\n",
    "print(f\"Average prediction time per sample: {average_time_per_sample:.4f} seconds\")\n",
    "print(f\"{args.model_type} done training; \\nTest: {test_l2 / ntest}, Test_nse: {test_nse / ntest}, Test_corr: {test_corr / ntest}, Test_csi_1: {test_csi_1 / ntest}, Test_csi_2: {test_csi_2 / ntest}, Test_csi_3: {test_csi_3 / ntest}\")\n",
    "summary = f\"Args: {str(args)}\" \\\n",
    "          f\"\\nParameters: {complex_ct}\" \\\n",
    "          f\"\\nTest: {test_l2 / ntest}\" \\\n",
    "          f\"\\nTest_nse: {test_nse/ntest}\" \\\n",
    "          f\"\\nTest_corr: {test_corr/ntest}\" \\\n",
    "          f\"\\nTest_csi_1: {test_csi_1/ntest}\" \\\n",
    "          f\"\\nTest_csi_2: {test_csi_2/ntest}\" \\\n",
    "          f\"\\nTest_csi_3: {test_csi_3/ntest}\" \\\n",
    "          f\"\\nSuper Space Test: {test_space_l2}\" \\\n",
    "          f\"\\nSuper Space Interpolation Test: {test_int_space_l2}\" \\\n",
    "          f\"\\nSuper S: {S_super}\" \\\n",
    "          f\"\\nSuper Time Test: {test_time_l2}\" \\\n",
    "          f\"\\nSuper Time Interpolation Test: {test_int_time_l2}\" \\\n",
    "          f\"\\nSuper T: {T_super}\" \n",
    "if swe:\n",
    "    summary += f\"\\nVorticity Test: {test_vort_l2 / ntest}\" \\\n",
    "               f\"\\nPressure Test: {test_pres_l2 / ntest}\"\n",
    "txt = \"results_test\"\n",
    "if args.txt_suffix:\n",
    "    txt += f\"_{args.txt_suffix}\"\n",
    "txt += \".txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b839228e-389d-4394-b005-2ba23f673b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#show water height, water velocity results are saved in same way, simply call 1, 2 at the last dimention. eg. pred[j, :, :, i, 1]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.colors as mcolors\n",
    "import tifffile as tiff\n",
    "from scipy.ndimage import zoom\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "del model\n",
    "example = tiff.imread('/home/sirui/INNOMAUS/2025_new/gt_b/r/145mm/r2d_bln1_swmm_r_145mm_0H.tif')\n",
    "example = np.nan_to_num(example , nan=-1)\n",
    "example = zoom(example,1/5,order=1)\n",
    "mask = np.zeros(example.shape)\n",
    "mask[np.where(example>=0)]=1\n",
    "plt.imshow(mask)\n",
    "plt.colorbar()\n",
    "pred=pred.cpu().numpy()\n",
    "yy=yy.cpu().numpy()\n",
    "mask_expanded = np.expand_dims(mask, axis=(0, -1, -2))\n",
    "mask_final = np.broadcast_to(mask_expanded, pred.shape)\n",
    "pred[mask_final == 0] = np.nan\n",
    "yy[mask_final == 0] = np.nan\n",
    "time_str = \"2024-05-28-00:05\"\n",
    "time_obj = datetime.strptime(time_str, \"%Y-%m-%d-%H:%M\")\n",
    "for i in range(0, 16):\n",
    "    j = 0  # select the 0 th batch\n",
    "    new_time = time_obj + timedelta(seconds=i*300)\n",
    "    t=new_time.strftime(\"%Y-%m-%d-%H:%M\")\n",
    "    figure = plt.figure(figsize=(30, 10))\n",
    "\n",
    "    # recolor\n",
    "    divnorm = mcolors.TwoSlopeNorm(vmin=0, vcenter=0.3, vmax=0.6)  # for pred and gt\n",
    "    divnorm_err = mcolors.TwoSlopeNorm(vmin=-0.5, vcenter=0, vmax=0.5)  # for error map\n",
    "\n",
    "    # pred result\n",
    "    sub1 = figure.add_subplot(131)\n",
    "    plt.imshow(pred[j, :, :, i, 0], norm=divnorm)#, cmap=\"GnBu\")  # white close to 0.3 \n",
    "    plt.title(f\"Prediction at {t} moment (m)\")\n",
    "    plt.colorbar()\n",
    "\n",
    "    # grount truth\n",
    "    sub2 = figure.add_subplot(132)\n",
    "    plt.imshow(yy[j, :, :, i, 0], norm=divnorm)#, cmap=\"GnBu\")  # 0.3 white close to 0.3 \n",
    "    plt.title(f\"Ground Truth at {t} moment (m)\")\n",
    "    plt.colorbar()\n",
    "\n",
    "    # error calculation\n",
    "    error = (yy[j, :, :, i, 0] - pred[j, :, :, i, 0])\n",
    "\n",
    "    # visualization\n",
    "    sub3 = figure.add_subplot(133)\n",
    "    plt.imshow(error, norm=divnorm_err)#, cmap=\"seismic\")  # white close to 0\n",
    "    plt.title(f\"Error at {t} moment (m)\")\n",
    "    plt.colorbar()\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd740e3-4cb3-4889-964d-0a8c64efa28d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
